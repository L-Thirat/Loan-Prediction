{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This chunk of code make it possible to use src functions\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from DSProject import DSProject\n",
    "from preprocess import *\n",
    "\n",
    "dsp = DSProject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target0 = dsp.read_table('group_payment_target', 'feature', use_schema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DSProject import min_date_train, max_date_train, min_date_test, max_date_test, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['dbsoc', 'cst_dim', 'sum_cc_bhvr_scor', 'sor_cc_ar_20160401_20161001'] #'sor_cc_ar_20170201_20170501',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train, target_test = filter_dates(target0, min_date_train, max_date_train, min_date_test, max_date_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = target_train\n",
    "test_set = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging feature dbsoc\n",
      "Delete single value column list\n",
      "['OSAMT_y']\n",
      "Number of column deleted\n",
      "1\n",
      "Delete single value column list\n",
      "['OSAMT_y']\n",
      "Number of column deleted\n",
      "1\n",
      "249112\n",
      "76313\n",
      "Merging feature cst_dim\n",
      "Delete single value column list\n",
      "['HASH_IP_ID_y']\n",
      "Number of column deleted\n",
      "1\n",
      "Delete single value column list\n",
      "['HASH_IP_ID_y']\n",
      "Number of column deleted\n",
      "1\n",
      "248987\n",
      "76290\n",
      "Merging feature sum_cc_bhvr_scor\n",
      "Delete single value column list\n",
      "['Previous_FileDate_y', 'Next_FileDate_y', 'HASH_IP_ID_y']\n",
      "Number of column deleted\n",
      "3\n",
      "Delete single value column list\n",
      "['Previous_FileDate_y', 'Next_FileDate_y', 'HASH_IP_ID_y']\n",
      "Number of column deleted\n",
      "3\n",
      "193265\n",
      "60376\n",
      "Merging feature sor_cc_ar_20160401_20161001\n",
      "Delete single value column list\n",
      "['Previous_FileDate_y', 'Next_FileDate_y', 'HASH_IP_ID_y', 'HASH_LPM_CST_ID_y', 'POSN_DT_y', 'CC_TP_ID_y', 'CST_TP_ID_y', 'BILL_CYC_ID_y', 'EFF_DT_y', 'CARD_TP_y']\n",
      "Number of column deleted\n",
      "10\n",
      "Delete single value column list\n",
      "['Previous_FileDate_y', 'Next_FileDate_y', 'HASH_IP_ID_y', 'HASH_LPM_CST_ID_y', 'POSN_DT_y', 'CC_TP_ID_y', 'CST_TP_ID_y', 'BILL_CYC_ID_y', 'EFF_DT_y', 'CARD_TP_y']\n",
      "Number of column deleted\n",
      "10\n",
      "193273\n",
      "60400\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    print('Merging feature ' + feature)\n",
    "    df0 = dsp.read_table(feature, 'feature', index_col=0, dtype={'HASH_AR_ID': str}, parse_dates=['FileDate'])\n",
    "    df_train, df_test = filter_dates(df0, min_date_train, max_date_train, min_date_test, max_date_test)\n",
    "    train_set = train_set.merge(df_train, on=['HASH_AR_ID', 'FileDate'], how='inner', suffixes=['', '_y'])\n",
    "    test_set = test_set.merge(df_test, on=['HASH_AR_ID', 'FileDate'], how='inner', suffixes=['', '_y'])\n",
    "    train_set = delete_excess_columns(train_set)\n",
    "    test_set = delete_excess_columns(test_set)\n",
    "    print(len(train_set.index))\n",
    "    print(len(test_set.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsp.write_table(train_set, 'train_' + train_label, 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsp.write_table(test_set, 'test_' + test_label, 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}